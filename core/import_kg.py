"""
Import knowledge graph data from JSON/CSV files into Neo4j database.
Run after build_kg_deepseek.py has generated the output files.
"""
import os
import json
import glob
from neo4j import GraphDatabase

# ================= é…ç½®åŠ è½½ =================
CONFIG_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "config.json")
with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    config = json.load(f)

NEO4J_URI = config["neo4j"]["uri"]
NEO4J_AUTH = (config["neo4j"]["username"], config["neo4j"]["password"])

# æ•°æ®æ¥æºç›®å½• (build_kg_deepseek.py çš„è¾“å‡ºç›®å½•)
OUTPUT_HISTORY_DIR = "output_history"
INPUT_DIR = "data"  # ä¹Ÿæ”¯æŒç›´æ¥å¯¼å…¥åŸå§‹æ–‡ä»¶

# ================= æ ¸å¿ƒé€»è¾‘ =================
driver = GraphDatabase.driver(NEO4J_URI, auth=NEO4J_AUTH)


def create_indexes(session):
    """åˆ›å»ºç´¢å¼•ä»¥åŠ é€ŸæŸ¥è¯¢"""
    indexes = [
        "CREATE FULLTEXT INDEX search_index IF NOT EXISTS FOR (n:Entity) ON EACH [n.name]",
        "CREATE INDEX entity_name_idx IF NOT EXISTS FOR (n:Entity) ON (n.name)",
    ]
    for idx in indexes:
        try:
            session.run(idx)
        except Exception as e:
            print(f"ç´¢å¼•åˆ›å»ºè·³è¿‡æˆ–å¤±è´¥: {e}")


def clear_database(session):
    """æ¸…ç©ºæ•°æ®åº“ä¸­çš„ç°æœ‰æ•°æ®ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰"""
    confirm = input("è­¦å‘Šï¼šè¿™å°†åˆ é™¤æ‰€æœ‰ç°æœ‰æ•°æ®ã€‚æ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ")
    if confirm.lower() != 'y':
        print("å·²å–æ¶ˆ")
        return False
    session.run("MATCH (n) DETACH DELETE n")
    print("å·²æ¸…ç©ºæ•°æ®åº“")
    return True


def import_json_triplets(session, json_path):
    """ä»JSONæ–‡ä»¶å¯¼å…¥ä¸‰å…ƒç»„"""
    print(f"ğŸ“„ æ­£åœ¨å¯¼å…¥: {json_path}")

    with open(json_path, 'r', encoding='utf-8') as f:
        triplets = json.load(f)

    if not triplets:
        print(f"  âš ï¸ ç©ºæ–‡ä»¶ï¼Œè·³è¿‡")
        return 0

    count = 0
    for t in triplets:
        head = t.get('head', '').strip()
        relation = t.get('relation', '').strip()
        tail = t.get('tail', '').strip()
        source = t.get('source', '')

        if not head or not relation or not tail:
            continue

        try:
            # åˆ›å»ºå®ä½“å’Œå…³ç³»
            session.run("""
                MERGE (h:Entity {name: $head})
                MERGE (t:Entity {name: $tail})
                MERGE (h)-[r:RELATION {type: $relation, source: $source}]->(t)
            """, head=head, tail=tail, relation=relation, source=source)
            count += 1
        except Exception as e:
            print(f"  âŒ å¯¼å…¥å¤±è´¥: {head} -[{relation}]-> {tail}: {e}")

    print(f"  âœ… æˆåŠŸå¯¼å…¥ {count} æ¡å…³ç³»")
    return count


def import_csv_triplets(session, csv_path):
    """ä»CSVæ–‡ä»¶å¯¼å…¥ä¸‰å…ƒç»„"""
    import pandas as pd

    print(f"ğŸ“„ æ­£åœ¨å¯¼å…¥CSV: {csv_path}")

    df = pd.read_csv(csv_path)
    if df.empty:
        print(f"  âš ï¸ ç©ºæ–‡ä»¶ï¼Œè·³è¿‡")
        return 0

    count = 0
    for _, row in df.iterrows():
        head = str(row.get('head', '')).strip()
        relation = str(row.get('relation', '')).strip()
        tail = str(row.get('tail', '')).strip()
        source = str(row.get('source', '')).strip()

        if not head or not relation or not tail or head == 'nan':
            continue

        try:
            session.run("""
                MERGE (h:Entity {name: $head})
                MERGE (t:Entity {name: $tail})
                MERGE (h)-[r:RELATION {type: $relation, source: $source}]->(t)
            """, head=head, tail=tail, relation=relation, source=source)
            count += 1
        except Exception as e:
            print(f"  âŒ å¯¼å…¥å¤±è´¥: {head} -[{relation}]-> {tail}: {e}")

    print(f"  âœ… æˆåŠŸå¯¼å…¥ {count} æ¡å…³ç³»")
    return count


def import_from_output_history(session):
    """ä» output_history ç›®å½•å¯¼å…¥æ‰€æœ‰æ•°æ®"""
    if not os.path.exists(OUTPUT_HISTORY_DIR):
        print(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {OUTPUT_HISTORY_DIR}")
        return 0

    json_files = glob.glob(os.path.join(OUTPUT_HISTORY_DIR, "**/*.json"), recursive=True)
    csv_files = glob.glob(os.path.join(OUTPUT_HISTORY_DIR, "**/*.csv"), recursive=True)

    total = 0
    for json_file in json_files:
        total += import_json_triplets(session, json_file)

    for csv_file in csv_files:
        total += import_csv_triplets(session, csv_file)

    return total


def import_from_directory(session, directory):
    """ä»æŒ‡å®šç›®å½•å¯¼å…¥æ–‡æ¡£ç›´æ¥è§£æï¼ˆéœ€è¦å…ˆè¿è¡ŒLLMæå–ï¼‰"""
    # å¦‚æœç›®å½•ä¸‹æœ‰å·²æå–çš„ä¸‰å…ƒç»„æ–‡ä»¶
    json_files = glob.glob(os.path.join(directory, "*.json"))
    csv_files = glob.glob(os.path.join(directory, "*.csv"))

    total = 0
    for json_file in json_files:
        total += import_json_triplets(session, json_file)

    for csv_file in csv_files:
        total += import_csv_triplets(session, csv_file)

    return total


def show_stats(session):
    """æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡:")

    # å®ä½“æ•°é‡
    result = session.run("MATCH (n:Entity) RETURN count(n) as count")
    entity_count = result.single()["count"]
    print(f"  å®ä½“æ•°é‡: {entity_count}")

    # å…³ç³»æ•°é‡
    result = session.run("MATCH ()-[r]->() RETURN count(r) as count")
    rel_count = result.single()["count"]
    print(f"  å…³ç³»æ•°é‡: {rel_count}")

    # å…³ç³»ç±»å‹åˆ†å¸ƒ
    print("  å…³ç³»ç±»å‹åˆ†å¸ƒ:")
    result = session.run("""
        MATCH ()-[r]->()
        RETURN r.type as type, count(r) as count
        ORDER BY count DESC
    """)
    for record in result:
        print(f"    {record['type']}: {record['count']}")


def main():
    print("=" * 50)
    print("Neo4j çŸ¥è¯†å›¾è°±å¯¼å…¥å·¥å…·")
    print("=" * 50)

    with driver.session() as session:
        # é€‰é¡¹èœå•
        print("\né€‰æ‹©å¯¼å…¥æ¨¡å¼:")
        print("1. ä» output_history å¯¼å…¥ (build_kg_deepseek.py çš„è¾“å‡º)")
        print("2. ä»æŒ‡å®šç›®å½•å¯¼å…¥")
        print("3. æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡")
        print("4. æ¸…ç©ºæ•°æ®åº“å¹¶é€€å‡º")

        choice = input("\nè¯·é€‰æ‹© (1-4): ").strip()

        if choice == "1":
            create_indexes(session)
            total = import_from_output_history(session)
            print(f"\nğŸ‰ æ€»è®¡å¯¼å…¥ {total} æ¡å…³ç³»")
            show_stats(session)

        elif choice == "2":
            directory = input("è¯·è¾“å…¥ç›®å½•è·¯å¾„: ").strip()
            if os.path.exists(directory):
                create_indexes(session)
                total = import_from_directory(session, directory)
                print(f"\nğŸ‰ æ€»è®¡å¯¼å…¥ {total} æ¡å…³ç³»")
                show_stats(session)
            else:
                print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {directory}")

        elif choice == "3":
            show_stats(session)

        elif choice == "4":
            if clear_database(session):
                print("æ•°æ®åº“å·²æ¸…ç©º")

        else:
            print("æ— æ•ˆé€‰æ‹©")


if __name__ == "__main__":
    main()
